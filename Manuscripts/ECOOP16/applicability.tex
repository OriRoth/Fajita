\Cref{Theorem:Gil-Levy} and its proof above provide
  a concrete algorithm for converting an EBNF specification of a fluent API into
its realization:
\begin{quote}
  \begin{enumerate}
    \item Convert the specification into a plain BNF form
    \urlref{http://lampwww.epfl.ch/teaching/archive/compilation-ssc/2000/part4/parsing/node3.html}.
    \item Convert this BNF into a definition of a DPDA. If conversion fails,
      then the given specification is not deterministic context-free.
    \item Convert this DPDA into a jDPDA. (Conversion is guaranteed to succeed.)
    \item Apply the proof to generate appropriate \Java type definitions, making sure to
        augment methods with code to maintain the fluent-call-list.
        Parsing the fluent-call-list can done either in each method,
        or lazily, when the product of the fluent API call chain is to
         be used.
  \end{enumerate}
\end{quote}
Although possible in theory, a practical tool that does all these 
  does not seem feasible. 
Part of the problem is the complexity of the 
  algorithms used, some of which, e.g., the DPDA and jDPDA equivalance have never been 
  implemented.
Yet another issue that clients of compiler-compiler have grown to expect 
  facililities such as means for resolving ambiguities, manipulation 
  of attributes, etc.
Also, for a fluent API to be elegant and useful, 
  it should support method with parameters whose parameters are also defined by a  fluent API:
these two APIs may mutually recursive and even the same. 
Support of these features through four or so algorithmic abstractions 
  is likely to be a formidable engineering task.

Yet another challenge is control of the compiler's  
  runtime.

The \Java compiler is the main computational tool we use
in this manuscript.
In particular, the \Java generics mechanism is what
boosted our expressiveness from the trivial \emph{regular languages}
set, to the practical, reasonable \emph{deterministic context-free languages} set.

Formal proof of correctness with proper induction hypothesis.

An interesting question that was raised during this research,
  is what the runtime complexity of the \Java compiler is.
The reason this question is interesting, is its implication
  on the computational expressiveness of type-encoding.

For example, if we recognized that the \Java parser spends
  linear time on its input, we could say that it's not
  likely that we can type-encode nondeterministic CFG\@.
The reason is the fact that the best known algorithms
  today for parsing general nondeterministic CFG,
  run in super quadratic time.
And it is highly unlikely that the type-checker of \Java incidentally
  found an algorithm that is practically perfect in big-O notation.

As we explored this venue, we discovered that the type-checker of
  \Java actually runs in exponential time.

Consider an encoding of an S-expression in type~\cc{Cons}
  defined in~\cref{Figure:compiler}.

\begin{wrapfigure}[6]r{27ex}
  \caption{\label{Figure:compiler} Encoding of an binary type tree}
  \javaInput[minipage,width=27ex,left=-2ex]{compiler.listing}
\end{wrapfigure}

Type \cc{Cons} takes two type parameters, \cc{Car} and \cc{Cdr} (denoting left and right branches).
Denote the return type of \cc{d()} is~$τ= \cc{Cons< Cons<Car, Cdr>, Cons<Car, Cdr> >}$.
Let~$σ$ denote the type of the \kk{this} implicit parameter to~\cc{d}.
Since~$τ= \cc{Cons<}σ,σ\cc{>}$, we have~$|τ|≥2|σ|$,
  where the size of a type is measured, e.g., in number of characters in its textual representation.
In a chain of~$n$ calls to \cc{d()}
\begin{equation}
  \label{Equation:n}
  \cc{(Cons<?,?>(null)).}\overbrace{\cc{d().}⋯\cc{.d()}}^{\text{$n$ times}}\cc{;}
\end{equation}
the size of the resulting type is~$O(2ⁿ)$.

\begin{wrapfigure}r{43ex}%
  \begin{minipage}{43ex}
  \caption{\label{Figure:compile-empiric} Compilation time
    (sec†{measured on an Intel i5-2520M CPU @ 2.50GHz~$⨉$4, 3.7GB memory, Ubuntu 15.04 64-bit, \texttt{javac} 1.8.0\_66}%
    ) \emph{vs.}
      length of call chain.
}
  \gnuplotloadfile[terminal=pdf,terminaloptions={crop size 2.5in,1.5in color enhanced font ",8" linewidth 1}]{../Figures/kill.gnuplot}
\end{minipage}
\end{wrapfigure}%

\Cref{Figure:compile-empiric} shows on the doubly logarithmic plane that the runtime (on a Lenovo X220)
of the \texttt{javac} compiler (version 1.8.0\_66) in face of a \Java program
  assembled from \cref{Figure:compiler} and \cref{Equation:n} placed as the
  single command of \cc{main()}.
We see that this runtime is asymptotically exponential.
(In fact, a variation of the construction may lead to even super-exponential growth rate of the size of types.)

We believe that this exponential growth is due to a design decision of the compiler.
Had the compiler used a representation of types that allows sharing of,
The footprint of exponentially sized types created by can be made linear
  with appropriate sharing of constituent types.
The above discussion, formalism and conjecture may seem at first sight too abstract
  and of little practical value.
Re-positioning perspective may shed a different light:~\cref{Theorem:Gutterman} is important not only because it tells us
  that the question of termination of a \CC compiler is as difficult
  the halting problem~\cite{Turing:1936}, but also because it
  justifies the high resource investment in
  template programming~\cite{Musser:Stepanov:1989,Dehnert:Stepanov:2000
  ,Backhouse:Jansson:1999, Austern:1998,Bracha:Odersky:Stoutamire:Wadler:98,X:Garcia:Jarvi:Lumsdaine:Siek:Willcock:03}.
