The \Java compiler is the main computational tool we use
  in this manuscript.
In particular, the \Java generics mechanism is what
  boosted our expressiveness from the trivial \emph{regular languages}
  set, to the practical, reasonable \emph{deterministic context free languages} set.

An interesting question that was raised during this research,
  is what the runtime complexity of the \Java compiler is.
The reason this question is interesting, is its implication
  on the computational expressiveness of type-encoding.

For example, if we recognized that the \Java parser spends
  linear time on its input, we could say that it's not
  likely that we can type-encode nondeterministic CFG\@.
The reason is the fact that the best known algorithms
  today for parsing general nondeterministic CFG,
  as mentioned in~\Cref{Section:preliminaries}, run in super quadratic time.
And it is highly unlikely that the type-checker of \Java incidentally
  found an algorithm that is practically perfect in big-O notation.

As we explored this venue, we discovered that the type-checker of
  \Java actually runs in exponential time.

Consider an encoding of an S-expression in type~\cc{Cons}
  defined in~\cref{Figure:compiler}.

\begin{wrapfigure}[6]r{27ex}
  \caption{\label{Figure:compiler} Encoding of an binary type tree}
  \javaInput[minipage,width=27ex,left=-2ex]{compiler.listing}
\end{wrapfigure}

Type \cc{Cons} takes two type parameters, \cc{Car} and \cc{Cdr} (denoting left and right branches).
Denote the return type of \cc{d()} is~$τ= \cc{Cons< Cons<Car, Cdr>, Cons<Car, Cdr> >}$.
Let~$σ$ denote the type of the \kk{this} implicit parameter to~\cc{d}.
Since~$τ= \cc{Cons<}σ,σ\cc{>}$, we have~$|τ|≥2|Σ|$,
  where the size of a type is measured, e.g., in number of characters in its textual representation.
In a chain of~$n$ calls to \cc{d()}
\begin{equation}
  \label{Equation:n}
  \cc{(Cons<?,?>(null)).}\overbrace{\cc{d().}⋯\cc{.d()}}^{\text{$n$ times}}\cc{;}
\end{equation}
the size of the resulting type is~$O(2ⁿ)$.

\begin{wrapfigure}r{43ex}%
  \begin{minipage}{43ex}
  \caption{\label{Figure:compile-empiric} Compilation time
    (sec†{measured on an Intel i5-2520M CPU @ 2.50GHz~$⨉$4, 3.7GB memory, Ubuntu 15.04 64-bit,javac 1.8.0\_66}%
    ) \emph{vs.}
      length of call chain.
}
  \gnuplotloadfile[terminal=pdf,terminaloptions={crop size 2.5in,1.5in color enhanced font ",8" linewidth 1}]{../Figures/kill.gnuplot}
\end{minipage}
\end{wrapfigure}%

\Cref{Figure:compile-empiric} shows on the doubly logarithmic plane that the runtime (on a Lenovo X220)
  of the ‟javac” compiler (version 1.8.0\_66) in face of a \Java program
  consisting of \cref{Equation:n} in its \cc{main()} and \cref{Figure:compiler}.
We see that this runtime is asymptotically exponential.
(In fact, a variation of the construction may lead to even super-exponential growth rate of the size of types.)

We however note that this exponential growth is due to a design decision of the compiler.
Had the compiler used a representation of types that allows sharing of,
The footprint of exponentially sized types created by can be made linear
  with appropriate sharing of constituent types.
