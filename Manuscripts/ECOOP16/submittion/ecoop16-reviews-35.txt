===========================================================================
                          ECOOP 2016 Review #35A
---------------------------------------------------------------------------
     Paper #35: Formal Language Recognition with the Java Type Checker
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert
                    Writing Quality: Q. Adequate

                         ===== Paper Summary =====

The paper presents an effective reduction from the membership
problem of DPDA (deterministic pushdown automata) to typechecking
in Java. The basic idea is to make Java's typechecker simulate a
run of the DPDA. However, the basic idea does not (obviously)
work because a DPDA may take an unbounded number of
epsilon-transitions between processing two letters of the input.
To avoid this issue, the DPDA is first converted to a
jump-deterministic DPDA, invoking a construction of (Courcelle,
1977).

Along the way, the paper introduces an interesting toolbox for
encoding basic computations into the Java type system, relying on
generics and on covariance of return types.

                    ===== Points For and Against =====

+ reduction from recognition of deterministic CFGs to Java type checking
+ nice toolbox of generics patterns
- no bounds on reduction
- weak impact on fluent APIs

                       ===== Detailed Comments =====

+ Reduction from Recognition of Deterministic CFGs to Java Type Checking.

Given a deterministic context-free language L (represented as a
deterministic pushdown automaton) the authors explain how to
construct a set of Java classes such that the membership question
"a1...an \in L?" reduces to typechecking the code
  a1().a2()...an()
Roughly, the type returned by ak() encodes the configuration of
the pushdown automaton after processing letter ak.

The proof has two parts. The first part is an unsurprising but
intricate and beautiful construction for simulating non-epsilon
transitions. The second part -- handling epsilon transitions --
is highly nontrivial! The authors solve it by invoking a result
of Courcelle from 1977, which is perhaps not widely known. Given
this result, the task reduces to adding an extra sprinkle of Java
generics hackery.

The result and the insight of the proof are both beautiful.  The
result is that recognition of deterministic CFLs reduces to Java
typechecking. The insight is that a constructive proof is
possible by invoking (Courcelle, 1977).


+ Nice Toolbox of Generics Patterns.

Before reading Section 5 I spent about a day to see if I can
reproduce the main result, claimed in Section 4. I was able to
come up with something that handles non-epsilon transitions (but
not epsilon transitions). More importantly, my solution was
orders of magnitude uglier than what I then found in Section 5.
Thus, I feel that the authors produced a nice and reusable
toolbox of techniques for encoding computation in Java's type
system. Section 6 extends this toolbox further.

(Speaking of Section 6 ... I had no idea why am I reading it
while I was reading it. The motivation comes -- rather as a shock --
at the beginning of Section 7: that's how epsilon transitions are
handled.)


- No Bounds on Reduction.

The constructions described in the paper are polynomial. However,
it is unclear what is the complexity of the whole reduction,
because we don't know whether the construction from (Courcelle,
1977) explodes the size of the automaton. I think it would be
nice to discuss briefly the complexity of the reduction, so that
readers don't have to go read other papers to figure it out.


- Weak Impact on Fluent APIs.

The motivation for the work is ostensibly to aid in the design of
fluent APIs (that is, those that chain many method calls).
However, I think this work will have little impact on the
practice of designing fluent APIs.


= Other.

I would mention much earlier that epsilon-transitions pose a
challenge. Otherwise, readers may think the task is easier than
it really is.

The authors state several times that there are no results on the
complexity of Java's type system. I am aware of some decidability
results on related type systems. The authors may wish to do a
literature search starting from this seed:
  [Kennedy, Pierce, On Decidability of Nominal Subtyping with Variance, 2006]

Section 8 contains an example of a Java program whose compilation
takes a long time. The example is connected to the rest of the
paper only loosely: it uses generics. Also, despite what the
authors claim, I doubt many readers will find it surprising that
the Java compiler sometimes takes a long time to finish. I think
it would be worth mentioning that the Java compiler may take a
long time *if* it actually happens for *your* construction, not
just for some loosely similar kind of Java program.

Although the text is organized well, it has many spelling and
grammar mistakes.  Please proofread it.

Here's a small selection of typos:
  - letters are sometimes a and sometimes \sigma (e.g., bottom of page 6)
  - in Fig 5.7, the } that ends the class is on line 1 but should be on line 12
  - on page 15, "k=|\Sigma|" should be "k=|\Gamma|"

           ===== Questions for Authors in Response Period =====

Does your encoding use features specific to Java 8, or does it
also work in previous versions? Otherwise put, which are the key
features of the type system on which you rely?

What exactly are you proving in footnote 16? Your article
presents an encoding of all DPDA into the Java type system, so
such an encoding is clearly *not* impossible as footnote 16 seems
to claim. Perhaps you want to prove the impossibility of dumb
encodings, for some definition of "dumb"?

This Paper Ought to Have an Accompanying Artifact:
                                     1. No, does not need to

===========================================================================
                          ECOOP 2016 Review #35B
---------------------------------------------------------------------------
     Paper #35: Formal Language Recognition with the Java Type Checker
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert
                    Writing Quality: P. Well-written

                         ===== Paper Summary =====

The paper presents a study of the expressiveness of the Java type system. Specifically, the paper investigates the extent to which Java supports type-safe fluent APIs. The main result of the paper is a proof that fluent APIs that represent deterministic context-free languages can indeed be encoded in Java. The encoding relies on generics and the fact that deterministic context-free grammars correspond to simple-jump single-state realtime deterministic pushdown automatons, which can be encoded in Java. The paper concludes that a mechanized generation of a fluent API is feasible, but the generated fluent API may impose exponential compilation time at least with javac.

                    ===== Points For and Against =====

+ The generation of fluent APIs is a relevant topic
+ Lower bound on expressiveness of fluent APIs in Java
+ Proof of the encodeability of DPDA-recognized languages as fluent APIs.
+ Innovative encoding using the jump-stack data structure

- No discussion of the tightness of the lower bound.
- No case study for some non-trivial example grammar (generate fluent API systematically but by hand)
- Generator for fluent APIs not implemented
- Practical applicability unclear

                       ===== Detailed Comments =====

This is an interesting paper. An additional perspective on the results of this work is that it connects external domain-specific languages (specified via a grammar) and shallowly embedded domain-specific languages (specified as an API).

The paper addresses two questions: What is the expressiveness of the Java type system? And how to systematically encode languages as fluent APIs in Java? For the former question, the paper provides convincing results, namely it shows that the Java type system can recognize deterministic CFGs. This results by itself is already an achievement and required a sophisticated encoding using jump stacks.

However, I am not convince that an answer to the expressiveness question provides good guidance on how to actually encode languages as fluent APIs. The paper should provide more evidence to this end. For one, it is not clear why the authors did not implement the generator for fluent APIs sketched in Section 8. Why is the conversion from DPDA to jDPDA challenging? Assuming it is, it would still be good to present and discuss a fluent API for a small but non-trivial grammar (like jOOQ) that uses the proposed generation scheme (applied by hand). The question here is whether the theoretical result on language recognition is actually applicable to the implementation of fluent APIs. For example, how would the generated fluent API construct an internal data structure corresponding to the abstract syntax tree?

           ===== Questions for Authors in Response Period =====

How tight is the lower bound of deterministic CFGs? How do advanced features of the Java type system like wildcards and intersection types affect this?

Regular expressions are easy to encode as a fluent API in Java. What is the relation between jDPDA and regular expressions with respect to the configuration space, the transition function, and their encodings?

This Paper Ought to Have an Accompanying Artifact:
                                     1. No, does not need to

===========================================================================
                          ECOOP 2016 Review #35C
---------------------------------------------------------------------------
     Paper #35: Formal Language Recognition with the Java Type Checker
---------------------------------------------------------------------------

                      Overall merit: A. Good paper, I will champion it
                         Confidence: X. I am an expert in this area
                    Writing Quality: P. Well-written

                         ===== Paper Summary =====

Fluent APIs are those designed to encourage method chaining, which
gives programmers an "illusion" that they use DSLs.  Viewing the set
of method sequences allowed by a type system as a formal language
(where method names are alphabets) naturally gives rise to the
following question: how expressive is the type system of language X in
terms of formal language recognition?  This paper gives an answer to
the question where X is Java: the author(s) show that the Java type
system can express any deterministic context-free language.

                    ===== Points For and Against =====

+ An elegant, theoretically interesting result

+ Useful techniques to express constraints internal DSLs implemented
in Java via fluent APIs.

- The theoretical result by itself may not be much of practical
  interest.

                       ===== Detailed Comments =====

It is a popular technique to use expressive type systems, e.g. those
of Haskell and Scala, to represent syntactic constraints on embedded
DSLs.  Although Java's type system is quite expressive (or
complicated, rather), there's been little work on its potential and
how to exploit the expressiveness in developing embedded DSLs.  The
result of the present work is somewhat surprising because the class of
deterministic context free languages is fairly large.

The presented techniques to encode push-down automata seem practically
useful when someone wants to design their own language.  Types
expressions used are admittedly fairly complicated, programmers (of a
DSL) do not necessarily see them because complicated types are given
to intermediate expressions.  (Resolving typing errors might
be difficult as in C++ template programming, though.)

The paper is well written, fun to read and easy to access (for me).
It develops encoding techniques gradually from basic to advanced ones
and, once one understands them, it is fairly easy to see that the main
theorem holds.  Those who are not very familiar with generics and
especially wildcards, however, may find it difficult to follow the
details, so the author(s) should give a brief overview of the Java
type system in the paper.

As discussed properly by the authors, the theoretical result by itself
doesn't mean this technique practically works for all deterministic
context-free languages.  The way the Java type system typechecks
programs is different from efficient CFL parsing and the time
complexity can be exponential.  It is unfortunate and seems hard to
overcome but, at least, it is a good thing that the authors analyze
the problem.

In summary, the presented work presents contributions that are
interesting both from theoretical and practical point of views.  It
has a practical motivation, presents a nice theoretical result and
practically useful insights.


Minor comments:

The footnote attached to the quote at the beginning of the paper seems
lost.

Abstract:
- idioms o [-> of]
- the may be

Section 1.
- Some more basics of fluent APIs should be provided.

p.3: "a fluent API that realize[s] any ..."

- The word "semantic" is an adjective; use "semantics" (which is an uncountable noun ending with "s").

- Kennedy and Pierce [FOOL/WOOD 2007] have discussed complexity
  (rather, decidability) of nominal type systems with variance.

p.4: "Not surprisingly, ..." doesn't form a sentence.

p.5: "There is [a] large body of research"

p.6: "More general[ly],"

p.6: Theoretically, there is LR(0), too.

p.6: Footnote 11 misses a period.

p.8: "import static these [-> ones]"

p.9: "Body of functions is" -> "Bodies of functions are"

Fig. 6.3: The comma before E on line 13 should be move to the preceding line.

p.20: "sharing of, of expressions"

This Paper Ought to Have an Accompanying Artifact:
                                     1. No, does not need to

===========================================================================
                          ECOOP 2016 Review #35D
---------------------------------------------------------------------------
     Paper #35: Formal Language Recognition with the Java Type Checker
---------------------------------------------------------------------------

                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it
                         Confidence: X. I am an expert in this area
                    Writing Quality: R. Needs improvement

                         ===== Paper Summary =====

This paper presents an approach to support fluent APIs in Java, that is,
a typing discipline whereby the sequence of methods invoked in complex
object construction expressions can be constrained. The expressible
legal sequences are the languages recognizable by a jDPDA, i.e., all
deterministic context-free languages, and they are enforced by a type
encoding of the jDPDA corresponding to the given language. The approach
is described based on an encoding of an example automaton in the space of
Java types, and the corresponding general encoding technique follows by
a generalization from there. Finally, the paper discusses how practical
the approach is at this point.

                    ===== Points For and Against =====

+ It represents a refreshing point of view on Java that it might be useful
  to employ type level encodings to enforce flexible disciplines upon the
  shape of expressions

+ If this approach is developed further, e.g., by means of a practical
  code generator, then it might be useful for programmers who just want
  to ensure that their APIs are used in ways that are intended to work.

- The paper is not very readable; in particular, it very often leaves the
  reader wondering "why do they do this?". Presumably it would be very
  useful if the paper were to be presented in a substantially different
  manner: Present the computations that you wish to perform using the Java
  type system as the nicest possible stand-alone calculus. Then, when the
  reader knows exactly what the goal is, show how the (rather messy)
  type level encoding can achieve the same thing.

- The claimed proof of theorem 1 is an informal presentation of the encoding
  of a single example. It is not even stated precisely that a proof would
  amount to a general technique, not a single example of an encoding. But
  the actual techniques would probably work in the general case, so the
  presentation could be made much more convincing if the generality were
  maintained explicitly along the way, and the example were presented as
  an example.

- It is not obvious that the approach is practical for Java programmers.
  The paper would benefit from making a clearer choice: It could be aimed
  at a practical goal, that is, an actual preprocessor that would
  manage all the complex encoding stuff for practical programmers, showing
  that it is useful to apply these techniques for the extra checking.
  Or it could take a more theoretical approach, considering the Java type
  system as a mathematical framework and showing something about the
  expressive power and its limits. Currently, the paper is neither
  practical enough nor theoretically precise enough to be really convincing.

                       ===== Detailed Comments =====

- Introduction: Could you make it a bit clearer what a fluent API is? The
current presentation makes sense after reading the page mentioned in
footnote 2, but on its own it is not easy to determine whether any given
API is or isn't fluent---and even the footnote document is quite vague.

- page 2, typo: 'always [a] Java type definition'

- End of 1.1: I suspect that you will "run an LR parser" on the fluent call
chain by encoding the parser mechanics in type arguments of polymorphic
methods. That sounds like a tour de force in terms of type argument
complexity, which makes it understandable that javac may choke on the
hypothetical compiler-compiler output (p3). That may all be fine, but it
doesn't smell terribly practical.

- p3, 'understanding .. fluent APIs': How can you claim that modeling fluent
APIs using formal languages helps _understanding_ them? Maybe the model
doesn't fit perfectly, in which case you may just help us misunderstand
them to some extent. It would at least be very useful to have some
arguments why this is a faithful and reasonably complete model, and if
such arguments are present in the paper then they should be briefly
introduced already here.

- p4 typo: 'and [the] such'

- p5, 'may be arbitrary': I suppose a main point is that they are not
arbitrary, it's a sequence that follows rules. Presumably you can
choose a phrase here to reinforce that point, rather than having this
phrase which might well confuse some readers.

- p6, typo: $a'$ should be $\sigma'$ in bullet point 2. Similarly for
bullet point 3 on p7, $a$ should be $\sigma$. Finally, the $a$ in bullet
4 should probably also have been $\sigma$.

- p7, 'exists a Java definition, $J_A$..': Java definitions have not been
modeled formally at this point, and neither has Java type checking. This
means that the theorem is informal in the sense that crucial parts of
the claim must be understood in their standard, informal sense. Did you
make any attempts to model this in a self-contained manner, or do you
really need every bit of expressive power of full-fledgeed, practical
Java type checking?

- p8 typo: 'sta[r]ting A.build variable'? 'sta[t]ic'? 'sub[yp]te' 'store the
[store the]'

- p8, 'the compile-time mechanism of Java': This phrase is extremely vague.

- p9, Fig. 5.1: Why do you use nesting with \Gamma', \Gamma, and \gamma1
and \gamma2? There is nothing in each nested class which causes the
nesting to be required. Also, the fact that it is static nesting rather
than inner classes is a hint that it may not be needed. [OK, a motivation
is given later, p10 item 2, but it would be nice to have that argument
when the thought arises that the construct is needlessly complex.]

- p10, Fig. 5.2: I don't understand the motivation for having functions
with arity different from one in the Java encoding: Whenever you have a
function with arity k you just take the finite sets S1 .. Sk and create
the set of tuples thereof (which is still finite), and then you have the
arity one case again and you should be able to use the approach for that.
Maybe you could give a concrete example to motivate why a programmer
would be more happy with an encoding for multiple arguments rather than
using a single argument that encodes a tuple in itself. Also, it does not
look very practical that you wish to encode finite sets with one or more
declarations per value; could you give a concrete example to support the
claim that we won't want sets of size, say, hundreds of values?

- p10, 'Genericity can be employed to serve this end': Sure, you can have
`List<C>`, `List<List<C>>` etc. and hence model the natural numbers,
and that's again enough to model any finite set. This is also the basic
idea behind Fig. 5.4, 5.5. But it is very difficult for the reader to
see how to interpret this, that is, how you are going to use it. So if
you can spot a certain amount of frustration in my comments it's probably
because I'm looking for an overall framework that these techniques can
fit into. Couldn't you reorganize the paper such that the reader gets a
fair chance to see where you are going? Then you wouldn't get all those
"why do you do that?" and "isn't that completely impractical?" and "how
big would those finite sets be?" complaints..

- p12, end of Sect.5: The description of `Peep` contains some of that
motivation that I've been waiting for. Thanks!

- p14, typos: 'is [a] computed', 'number o[f] steps'

- p15, 'proof .. is .. reduced to type-encoding of a given jDPDA': Please
make this statement more precise. Obviously, it's about having a systematic
approach that will encode any given jDPDA, not just being able to handle
one example.

- p15, typo: '$k = |\Sigma|$' --> '$k = |\Gamma|$' maybe?

- p16, 'raw type C': Please give a hint why the raw type would work in a
way that makes sense for the given context.

- p16, typo: 'sta[r]ting point', and at least one more occurrence of
'stating'.

- Fig. 7.1: Checking with footnote 17, I don't understand why
`isL(build.\sigma2().$())` would be accepted, nor why `isL(build.$())`
would be rejected. Several others also look wrong, and in particular
there must always be an even number of \sigma2() calls for acceptance.
Is footnote 17 just totally wrong?!

- Fig. 8.1: It is interesting that you show that javac is unable to handle
large generic types economically by sharing the representation of identical
subexpressions. But since you wouldn't expect anyone to write one of those
2^10 size type expressions explicitly, you are relying crucially on
the relevance of large generic types that never get used explicitly in
programs (because they are the types of expressions, never the types of
variables or parameters), and you could reasonably claim that this is a
pathological case. "Just don't do that in Java". ;-) Or could you argue
convincingly that there could exist meaningful Java programs where such
large types occur during type checking, but never need to be written
explicitly? It is not obvious to me that your jDPDA encoding would give
rise to exponentially sized types.

           ===== Questions for Authors in Response Period =====

Are you mainly interested in the theoretical point of view ("it is
possible to encode jDPDAs in the Java type system") or in the
practical point of view ("our technique will help Java programmers
write more correct programs")? Maybe both? If the practical point of
view is important, can you compare your technique to an ad-hoc
analysis (e.g., arguing that a stand-alone fluent api usage checker
solving the same problems as your approach would be difficult to
write, or inconvenient to use).

This Paper Ought to Have an Accompanying Artifact:
                                     1. No, does not need to

