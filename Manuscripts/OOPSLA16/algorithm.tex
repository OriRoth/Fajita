%! TEX root = 00.tex

The main effort of this section is in explaining the algorithm
for converting an LL grammar into \RLLp, a parsing automaton equipped with a stack
that has the unique quality of spending constant time on each read input.
This realtime property is crucial to the implementation language recognizers
with \Java types implementation.

When this is achieved, all that remains is the ‟compilation”' of the \RLLp into
\Java types. The challenging part of this translation is dealing
with the ‟JLS”, a data structure on which the \RLLp relies.

This data structure has been used before, e.g., for efficient management of the
runtime environment in programming languages with dynamic scoping, i.e.,
languages such as \Lisp, in which name resolution is with respect to previous
bindings made on the run time stack (disregarding the usual scoping and nesting
rules in languages such as \Pascal).

Interestingly, the JLS data structure is just another name for the ‟\emph{Jump
Deterministic PushDown Automata}" (JDPDA), a theoretical model used in the
study of automata and formal languages (see e.g.,~\cite{Linna:79,Courcelle:77}).
And, Incidentally, this JDPS is the one used by Gil and
Levy~\cite{Gil:Levy:2016}, in their proof that the \Java type checker can
recognize DCFG languages. Using their construction, the translation to \Java is
rather mechanical.

\subsection{The Realtime LL Parser}
\label{section:realtime}
The \emph{\textbf Realtime \textbf Left-to-right \textbf Leftmost-derivation
  Parser} (\RLLp), is a variant of the famous LL(1) parser~\cite{Lewis:66}. The
adjective realtime is to claim that:

\begin{itemize}
  \item an \RLLp examines its input only after consuming it, and,
  \item an \RLLp conducts at most one (potentially extended) stack operation in
        each step.
\end{itemize}

An extended stack operation is either a~$\Function push(α)$ of a string of
symbols, or a long~$\Function jump(·)$ into the stack position denoted
by its argument, involving an unbounded number of~$\Function pop()$ operation.

The stack symbols of an \RLLp are \emph{items}, where an item is pair of a
grammar rule and a ‟\emph{dot}”, written as
\[
  A ::= Y₀…Y_{i-1}·Yᵢ…Yₖ
\]
Formally, the dot is an integer, ranging from 0 to the length of the right-hand
side of the rule. But it is better to think of it as a notation for the prefix
of this right-hand side.

An item represents these precise moments in the analysis process of the
input in which:
\begin{itemize}
  \item all symbols included in this prefix have been successfully parsed, and,
  \item all symbols that lie after this prefix, are awaiting their turn
        to be parsed.
\end{itemize}

Items can be thought of as a generalization of the stack symbols of an \LLp
(recall that these are the grammar's terminals and nonterminals). \LLp stack
symbols are markers of the next symbol to be read or parsed. \RLLp stack
symbols store this information as well: The next symbol to be read or parsed,
is simply the symbol that follows that dot. The generalization is in adding to
this symbol the context of containing rule and the point of derivation within
it.

Just like the \LLp, the \RLLp is a stack automaton equipped with a prediction
table, whose next action is a function (realized in the prediction table) of
the next input symbol and the item present at the stack's top.

The \RLLp is initialized with the stack containing an item denoting the
degenerate prefix of a rule for deriving the start symbol. In case there are
more than one such rule, the automaton selects the rule dictated by the first
input token. (This rule is uniquely determined since the grammar is LL.)

After this initialization, the \RLLp proceeds following the instructions
in~\cref{algorithm:rll-parser}.

\begin{algorithm}
  \caption{\label{algorithm:rll-parser}
    A high level sketch of the iterative step of an \RLLp
  }
  \begin{algorithmic}[1]
    \LET{$[X ::=α·Yβ]$}{\Function pop()}\COMMENT{retrieve parsing state}
    \LET{$t$}{$\Function next()$}\COMMENT{examine input once per iteration}
    \IF[was rule fully parsed?]{$|Yβ|=0$}
      \IF{$X$ is not the start symbol}
         \STATE{$\Function jump(t)$}\COMMENT{pop this, potentially other items}
         \CONTINUE\COMMENT{restart, popping a new item}
      \FI
      \IF[$X$ must be the start symbol]{$t=\$$}
        \STATE{\textsc{Accept}}\COMMENT{start symbol fully parsed}
      \ELSE[start symbol parsed, but not all input consumed]
        \STATE{\textsc{Reject}}\COMMENT{\RLLp halts in error}
      \FI % Not anticipated EOF
    \FI % Was rule fully parsed?
    \IF[$Y$ is a terminal]{$Y∈Σ$}
      \IF[read terminal is not anticipated~$Y$]{$Y≠t$}
        \STATE{\textsc{Reject}}\COMMENT{\RLLp halts in error}
        \ELSE[anticipated terminal found on input, proceed]
      \STATE{$\Function push(X::=αY·β)$}\COMMENT{push item with dot advanced}
      \CONTINUE\COMMENT{restart, popping this item, and parsing~$β$}
      \FI % Not anticipated input token
    \FI % Y is a terminals
    \STATE{\textbf{assert}~$Y∈Ξ$}\COMMENT{$Y$ must be a nonterminal}
    \LET{$a$}{$\Function Δ(Y, t)$}\COMMENT{$Δ(Y,t)$ says what to do with~$Y$}
    \IF[input~$t$ was unanticipated]{$a=⊥$}
      \STATE{\textsc{Reject}}\COMMENT{\RLLp halts in error}
    \FI
    \IF[a string of~$ℓ$ items to push]{$a=I₁,…,I_ℓ$}
      \STATE{$\Function push(I₁, …, I_ℓ)$}
      \CONTINUE\COMMENT{restart with a somewhat deeper stack}
    \FI
    \STATE{\textbf{assert}~$a$ represents a jump} \COMMENT{$t$ indicates that~$Y \stackrel*⇒ε$}
    \STATE{$\Function jump(t)$}\COMMENT{pop this, potentially other items}
  \end{algorithmic}
\end{algorithm}

Comparing \cref{algorithm:rll-parser} with the LL-parsing algorithm
(\cref{algorithm:ll-parser}), we see that they both begin with popping a stack
symbol. More similarities are apparent, after observing that the next
symbol to read or parse, denoted by~$X$ in \cref{algorithm:ll-parser} is obtained
by extracting the symbol~$Y$ that follows the dot in the item~$X$ in
\cref{algorithm:rll-parser}.

In some ways, our \RLLp emulates an \LLp except that it attaches to each symbol
the rule in which it was found and the location within this rule.
(Thus, a push of single item is equivalent to the loop of push operations in
line 20 in \cref{algorithm:ll-parser}).

Function~$Δ(·,·)$, the transition function of an \RLLp is also a bit more
general, and may command the algorithm to push a sequence of stack symbols
(items), or carry out a jump into the stack.

\subsection{The Jump Stack Map Structure}
\label{section:jump}
We still need to explain how the meaning jump operations of \RLLp (lines~5
and~25 in \cref{algorithm:rll-parser}) are implemented. For this purpose, we
construct here the \emph{\textbf Jump \textbf Stack \textbf Map} (JSM).

Let~$S₀$ be the implicit stack of items used by the \RLLp, and suppose that
this stack is implemented as a singly linked list of nodes of an appropriate
type.

The top item of a stack (and in particular~$S₀$) is represented by a pointer,
called the ‟\emph{top pointer}”. This pointer can be used for pushing or
popping from the list. It can also be used for pushing into the stack a
pre-made string of items as done in line 22 of the \RLLp algorithm.

Storing pointers into designated items that lie deeper in the stack makes it
possible to make a direct jump into these items. We call these pointers
‟\emph{jump pointers}” and use the letter~$J$ to denote the type of these.

Let us now build on top of~$S₀$ an abstract data type~$D$, which can thought of
as a stack of dictionaries, supporting ordinary push and pop operations:
\[
  D=dₙ⋯d₁\$
\]
where~$dᵢ$,~$i=1…n$ is a (partial) map of the type~$Σ↛J$ ($Σ$ being our
alphabet,~$dₙ$ being the top of the stack and~$d₁$ the deepest item in it).

Sending query~$\Function get(t)$ to~$D$,~$t∈Σ$ returns the~$J$ value
associated with~$t$ in the top most (maximal~$i$) dictionary~$dᵢ$, which
satisfies~$t∈dᵢ$. The query returns~$⊥$ if~$t$ is not found in any of
the~$dᵢ$s.

There is an efficient implementation of~$D$ in which~$\Function get(t)$
is~$O(1)$ time, regardless of the depth at which~$t$ is found in~$D$, while
keeping updates of the form~$\Function push(d)$ or~$d←\Function pop()$
in~$O(|d|)$ time ($|d|$ being the size of the partial function).

In fact, since~$D$ has the same semantics as that of the stack of binding in
dynamically scoped language†{a dictionary~$dᵢ$ is a collection of
  names and their binding to nameable entities defined in the scope, which hide
the definitions made in containing scopes} definitions (such as
\TeX~\cite{TeX:79}), we can rely on the classical method~\cite{Schoe:95} for
implementing these

\begin{enumerate}
  \item Maintain a hash table~$H$ mapping each~$t∈Σ$ to a \emph{stack}~$s(t)$
        of values of type~$J$. A search for key~$t\inΣ$, then returns in~$O(1)$
        time the value at the top of~$s(t)$ or~$⊥$ if stack~$s(t)$ is empty.

  \item The call~$\Function push(d)$,~$|d|=m$ is implemented in~$O(m)$ time. Let
        \[
          d=❴(t₁,j₁),…,(tₘ,jₘ)❵.
        \]
        Then iterate over the pairs~$(tᵢ, pᵢ)$,~$i=1,…,m$,
        pushing~$pᵢ$ to stack~$s(tᵢ)$.

        The call~$\Function push(d)$ terminates by pushing~$d$ itself
        (represented, say, as linked list) as a single item into an auxiliary stack,
        to be denoted~$S₁$.

  \item Thus, abstract data type~$D$ is implemented as the pair~$⟨S₁,H⟩$.

        When~$D$ pops a map~$d$, it uses~$S₁$ to locate~$d$, and just before
        returning it, the implementation of~$D$ uses this~$d$ to pop an element
        from the set~$s(dᵢ)$ of stacks in~$H$,
        \[
          s(dᵢ) = ❴s(t) \;|\; t∈dᵢ❵.
        \]
\end{enumerate}

Let us now generalize~$D$ so that it also supports jumps into it. To do so, let
clients of~$D$ store pointers to designated dictionaries in the stack~$S₁$.

Upon jumping to a deep dictionary~$dᵢ$, our generalized~$D$ must be able to do
a constant time jumps in all stacks in~$s(dᵢ)$.

For this to happen we equip each~$dᵢ$ in the stack~$S₁$ with the correct jump
pointers into the these stacks.
The value of these jump pointers is set as the top pointers of stacks~$s(t)$ at
the time~$dᵢ$ was pushed into~$D$.

A jump into~$D$, yielding a dictionary of size~$m$ can now be implemented
in~$O(m)$ time:
The jump pointer into stack~$S₁$ yields a dictionary~$d$ stored in it.
In~$d$ we find~$m$ jump pointers into the~$m$ stacks~$s(d)$ in~$H$,
carrying out the these~$m$ jumps, concludes the jump operation on~$D$.

The final step in constructing the JSM is by coordinating
stacks~$S₀$ and~$S₁$:
\begin{itemize}
  \item A push operation on stack~$S₀$ is required to push, a (potentially
        empty) dictionary into the stack~$S₁$.
  \item A pop operation (the first command at every step of~\cref{algorithm:rll-parser})
        on stack~$S₀$ forces a pop operation of stack~$S₁$.
  \item Augment items in stack~$S₀$ to include also the jump pointer to
        the dictionary it pushed into~$S₁$.
  \item Let a jump into stack~$S₀$ also
        force a jump into the stack~$S₁$.
        (As expected, a jump into an item~$i$ means also a jump
        in stack~$S₁$ to dictionary~$dᵢ$.)
\end{itemize}
Thus, the linearly sized JSM data structure keeps its two
duties: supporting jumps into the items stack,
and maintaining a current map of the jumps to carry out at each item.
This map is updated with every push, which might
override (or add) entries to it.
Most importantly, this map is correctly restored
in the process of long jumps into the items stack.

\subsection{The Jumps Dictionary}
How should the JSM be used by the algorithm that generates
a specific \RLLp?

Jump operations are all at the responsibility of the JSM,
which maintains the information required to support these.
But, in order to be able to do this, the generator must
provide the \RLLp with the contents dictionary~$D$ that should be pushed to
to~$S₁$, the~$dᵢ$s, together with the push to~$S₀$ (lines~15 and~22 in
\cref{algorithm:rll-parser}).

In particular, the \RLLp generator must compute for each
item~$i∈I$, the dictionary~$\Function Jumps(i)$ which
map each token~$t$ that triggers a jump with
respect to~$i$, to~$t$'s jump value.
\Cref{algorithm:coordination} is the algorithm for doing so.

\begin{algorithm}
  \begin{algorithmic}
  \caption{\label{algorithm:coordination}
    Function~$\Function Jumps(i)$ returning, for an item~$i∈I$,
  the dictionary~$d$ mapping each token~$t$ that
    triggers a jump with respect to~$i$, to~$t$'s jump value.
  }
  \LET{$[A::=α·Y₁…Yₙ]$}{$i$} \COMMENT{break~$i$ into components}
  \LET{$d$}{$∅$} \COMMENT{initialize return variable}
  \FOR[for all symbols in suffix of~$i$]{$j = 1,…,n$}
  \IF[continue to build~$d$?]{not~$\Function Nullable(Y₁…Y_{j-1})$}
      \BREAK
    \FI
    \FOR[symbols that might cause jump in~$Y₁$]{$t∈\Function First(Yⱼ)$}
    \IF[\nth{1} update of key~$t$ in dictionary~$d$?]{$d(t)=⊥$}
      \STATE{$d(t) = [A::=αY₁…·Yⱼ…Yₙ]$} \COMMENT{update~$d(t)$}
      \FI
    \ENDFOR % Symbols
  \ENDFOR
  \RETURN{$d$}
  \end{algorithmic}
\end{algorithm}

Let~$β= Y₁…Yₙ$ be the suffix denoted by~$i$'s dot.
Then, for each terminal~$t∈Σ$,
function~$\Function Jumps(i)$ determines the shortest
prefix~$Y₁…Y_{j-1}$ of~$β$ which is nullable
and such that~$k ∈ \Function First(Yⱼ)$.
The following line of thought explains the rationale.

Assume that~$Y₁…Y_{j-1}$ is nullable and
that~$t∈\Function First(Yⱼ)$, for some~$t\inΣ$.
Then, when the \RLLp is at states described by~$i$ and~$t$
is seen, the \RLLp should conclude that~$Y₁…Y_{j-1}\stackrel * ⇒ε$
and jump forward to the point of the parsing process just before
seeing~$Yⱼ$.

This point in parsing is exactly the item obtained
from~$i$ by moving the dot to just before~$Yⱼ$.

One subtlety applies though.
In the case that the assumption holds for
both~$j$ and~$j'$,~$j < j'$ for the same token~$t$, there are
two alternatives to choose from:
\begin{itemize}
  \item~$Y₁…Y_{j-1}\stackrel * ⇒ε~$ and~$t$ is the first token in the derivation of~$Yⱼ$ i.e.\[
  Yⱼ \stackrel * ⇒ tγ.
\]
\item~$Y₁…Y_{j'-1}\stackrel * ⇒ε~$ and~$t$ is the first token in the derivation~$Y_{j'}$ i.e.,\[
Y_{j'} \stackrel * ⇒ tγ'.
\]
\end{itemize}
Recalling that an \LLp pushes
stack symbols in reverse order and that \RLLp emulates its behavior, we can
see that~$Y_{j'}$ is never given the opportunity to derive~$t$.

\subsection{Consolidating Push Operations }
Recalling \cref{substitution-factor}, capturing the notion of
repeated substitution, we realize that the \RLLp-generator
must consolidate~$k'$ push operations into one.

Function~$\Function Consolidate(i,t)$ in \cref{algorithm:consolidate}
returns the consolidated list of consecutive push operations conducted
by the \RLLp parser in state~$i$ and encounters terminal~$t$.
This is achieved by figuring out, ahead-of-time,
the operations of the \LLp.

Function~$\Function Consolidate(·,·)$ is invoked by the \RLLp generator
to pre-compute the consolidated list of push operations for all relevant
item-token pairs.
At runtime, the \RLLp will push the consolidated lists in constant time,
irrespective of the length of the consolidated list.

\begin{algorithm}[htb]
  \caption{\label{algorithm:consolidate}
    Function~$\Function Consolidate(i,t)$ pre-computing~$L$, the list of push
    operations that happen when an item~$i$ at the top of an \RLLp's stack
    encounters terminal~$t∈Σ∪❴\$❵$ on the input.
  }
  \begin{algorithmic}
    \STATE{$[X::=α·Yβ] ← i$} \COMMENT{break~$i$ into its components}
    \LET{$L$}{$∅$} \COMMENT{initialize return value}
    \WHILE[loop while~$Y$ is a nonterminal]{$Y∉Σ$}
      %\STATE{$\Function print(r)$} \COMMENT{useful for parsing}
      \STATE{$\Function push(L,[X ::=αY·β])$}\COMMENT{advance the item}
      \STATE{$r←δ(Y,t)$} \COMMENT{next rule to apply}
      \STATE{$[B::=X₁…Xₘ]←r$} \COMMENT{break~$r$ into components}
      \IF[$δ$ returned an~$ε$-rule]{$X₁…Xₘ=ε$}
        \WHILE[pop all exhausted rules]{$\Function exhausted(\Function peek(L))$}
          \STATE{$\Function pop(L)$}
        \ENDWHILE
      \ELSE[$δ$ returned a non~$ε$-rule]
        \STATE{$\Function push(L,r)$} \COMMENT{we now turn to parse~$r$}
      \FI
      \STATE{$[X::=α·Yβ] ← \Function pop(L)$} \COMMENT{break~$i$ into its components}
    \ENDWHILE
    \STATE{$\Function push(L,[X ::=αY·β])$} \COMMENT{$Y$ must be~$t$}
    \RETURN{$L$} \COMMENT{return the items to push}
  \end{algorithmic}
  \vspace{0.3ex}
  \hrule
  \vspace{0.3ex}
  \scriptsize
  \begin{itemize}
    \item List~$L$ is used in the main loop of the code to emulate the
          runtime stack of the generated \RLLp, and thus, pre-compute the net effect
          of stack operations that take place in
          configuration~$⟨i,t⟩$ until~$t$ is consumed.
          \par
          Accordingly, the emulation applies stack
          functions~$\Function pop(·)$ and~$\Function peek(·)$
          as well as operation~$\Function push(·,·)$ on the list~$L$,
          as if it were a stack.
          \par
          Calling~$\Function (·)$ on the emulation stack~$L$ at the time an
          \RLLp is generated, obviates the need for the \RLLp to~$\Function
          peek()$, at runtime, into its own stack.
    \item
          The algorithm relies on function~$\Function exhausted(i)$ that returns
          true for an item~$i$ when its dot is in its right most position,
          i.e., the item represents times during parsing in which all
          right hand side symbols of the item's rule have been parsed.
          \par
          Figuratively, an item~$i$ is exhausted right after the rule's body
          have been seen in full, and the item ‟waits” for the \RLLp to take
          the stack action appropriate when the rule reduces, and items representing
          it are no longer need.
  \end{itemize}
\end{algorithm}

\subsection{Putting the Pieces Together}
Generating an \RLLp for a given LL grammar requires providing to the
built-in algorithm of the \RLLp, the specific information it needs to
realize the given grammar.

Reexamining the code of the \RLLp (\cref{algorithm:rll-parser})
we see that all such information is contained in
function~$\Delta$.
Therefore, the core of the \RLLp generator is
\cref{algorithm:main} that computes~$\Delta$.

\begin{algorithm}[H]
  \caption{\label{algorithm:main}
    Compute contents of prediction table
    (transition function) entry~$Δ[i,t]$
    for all item~$i∈I$, token~$t ∈Σ$ pairs
    for which this entry is defined.
  }
  \begin{algorithmic}
    \FOR[for each item]{$i∈I$}
    \LET{$[A::=α·Yβ]$}{$i$} \COMMENT{break~$i$ into components}
      \IF[$Δ$ doesn't handle terminals]{$Y∈Σ$}
        \CONTINUE \COMMENT{handle next item.}
      \FI
      \FOR[calculate entry~${Δ[i,t]}$]{$t∈Σ$}
        \IF[$t$ is consumed while parsing~$i$]{$t∈\Function First(Yβ)$}
          \LET{$L$}{$\Function Consolidate(i,t)$}
          \LET{$Δ[i,t]$}{$\textcolor{red!70!black}{\texttt{[}}\Function Push(L)\textcolor{red!70!black}{\texttt{]}}$} \COMMENT{a push operation}
        \ELSIF[$t$ is consumed after parsing~$i$]{$t∈\Function Follow(A)$}
          \STATE{\bfseries\scriptsize{\texttt{// }\textit{Obtain jumps dictionary and store in~$\Delta$:}}}
          \LET{$Δ[i,t]$}{$\textcolor{red!70!black}{\texttt{[}}\Function Jumps(t)\textcolor{red!70!black}{\texttt{]}}$} \COMMENT{a jump operation}
        \FI
      \ENDFOR % for all terminals
    \ENDFOR % for all items
  \end{algorithmic}
\end{algorithm}

Recall that we manage the ‟$k^*$” phenomena using jumps, and that the
jumps are realized by the sophisticated JLS data structure that drives the
\RLLp.

The contract between the \RLLp and its generator is that function~$\Delta$
supplies the dictionaries that need to be pushed (and later jumped to)
by the JLS.

This information is retrieved by the \RLLp from the~$\Delta$ table,
and used and~$\Function push(·)$ed accordingly into the JLS.
Only with the aide of this information, the underlying JLS can support the
constant-time jumps (lines 5 and 25).

For this reason, \cref{algorithm:main} consults function~$\Function Jumps(·)$
to compute this dictionary storing it in the~$\Delta$ table.

Another part of the contract between the parser and its generator deals
with the~‟$k'$” phenomena. The generator invokes function~$\Function
Consolidate(·)$ (\cref{algorithm:consolidate}) to
compute~$L$, the consolidated list of push operations. List~$L$ will be later
read by \RLLp (line 18 in \cref{algorithm:rll-parser}).
