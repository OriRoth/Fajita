%! TEX root = 00.tex

\subsection{The Realtime LL Parser}
\label{section:realtime}
The \emph{\textbf Realtime \textbf Left-to-right \textbf Leftmost-derivation
Parser} (\RLLp), is a variant of the famous LL(1) parser~\cite{Lewis:66}. The
adjective realtime is to claim that:

\begin{itemize}
  \item an \RLLp examines its input only after consuming it, and,
  \item an \RLLp conducts at most one (potentially extended) stack operation in
        each step.
\end{itemize}

An extended stack operation is either a~$\Function push(α)$ of a string of
symbols, or a long~$\Function jump(·)$ into the stack position denoted
by its argument, involving an unbounded number of~$\Function pop()$ operation.

The stack symbols of an \RLLp are \emph{items}, where an item is pair of a
grammar rule and a ‟\emph{dot}”, written as
\[
  \<A> ::= Y₀…Y_{i-1}·Yᵢ…Yₖ
\]
Formally, the dot is an integer, ranging from 0 to the length of the right-hand
side of the rule. But it is better to think of it as a notation for the prefix
of this right-hand side.

An item represents these precise moments in the analysis process of the
input in which:
\begin{itemize}
  \item all symbols included in this prefix have been successfully parsed, and,
  \item all symbols that lie after this prefix, are awaiting their turn
        to be parsed.
\end{itemize}

Items can be thought of as a generalization of the stack symbols of an \LLp
(recall that these are the grammar's terminals and nonterminals). \LLp stack
symbols are markers of the next symbol to be read or parsed. \RLLp stack
symbols store this information as well: The next symbol to be read or parsed,
is simply the symbol that follows that dot. The generalization is in adding to
this symbol the context of containing rule and the point of derivation within
it.

Just like the \LLp, the \RLLp is a stack automaton equipped with a prediction
table, whose next action is a function (realized in the prediction table) of
the next input symbol and the item present at the stack's top.
token without consuming it.

The \RLLp is initialized with the stack containing an item denoting the
degenerate prefix of a rule for deriving the start symbol. In case there are
more than one such rule, the automaton selects the rule dictated by the first
input token. (This rule is uniquely determined since the grammar is LL.)

After this initialization, the \RLLp proceeds following the instructions
in~\cref{algorithm:rll-parser}.

\begin{algorithm}
  \caption{\label{algorithm:rll-parser}
    A high level sketch of the iterative step of an \RLLp
  }
  \begin{algorithmic}[1]
    \LET{$[X ::=α·Yβ]$}{\Function pop()}\COMMENT{retrieve parsing state}
    \LET{$t$}{$\Function next()$}\COMMENT{examine input once per iteration}
    \IF[was rule fully parsed?]{$|Yβ|=0$}
      \IF{$X$ is not the start symbol}
         \STATE{$\Function jump(t)$}\COMMENT{pop this, potentially other items}
         \CONTINUE\COMMENT{restart, popping a new item}
      \FI
      \IF[$X$ must be the start symbol]{$t=\$$}
        \STATE{\textsc{Accept}}\COMMENT{start symbol fully parsed}
      \ELSE[start symbol parsed, but not all input consumed]
        \STATE{\textsc{Reject}}\COMMENT{\RLLp halts in error}
      \FI % Not anticipated EOF
    \FI % Was rule fully parsed?
    \IF[$Y$ is a terminal]{$Y∈Σ$}
      \IF[read terminal is not anticipated~$Y$]{$Y≠t$}
        \STATE{\textsc{Reject}}\COMMENT{\RLLp halts in error}
        \ELSE[anticipated terminal found on input, proceed]
      \STATE{$\Function push(X::=αY·β)$}\COMMENT{push item with dot advanced}
      \CONTINUE\COMMENT{restart, popping this item, and parsing~$β$}
      \FI % Not anticipated input token
    \FI % Y is a terminals
    \STATE{\textbf{assert}~$Y∈Ξ$}\COMMENT{$Y$ must be a nonterminal}
    \LET{$a$}{$\Function Δ(Y, t)$}\COMMENT{$Δ(Y,t)$ says what to do with~$Y$}
    \IF[input~$t$ was unanticipated]{$a=⊥$}
      \STATE{\textsc{Reject}}\COMMENT{\RLLp halts in error}
    \FI
    \IF[a string of~$ℓ$ items to push]{$a=I₁,…,I_ℓ$}
      \STATE{$\Function push(I₁, …, I_ℓ)$}
      \CONTINUE\COMMENT{restart with a somewhat deeper stack}
    \FI
    \STATE{\textbf{assert}~$a$ represents a jump} \COMMENT{$t$ indicates that~$Y \stackrel*⇒ε$}
    \STATE{$\Function jump(t)$}\COMMENT{pop this, potentially other items}
  \end{algorithmic}
\end{algorithm}

Comparing \cref{algorithm:rll-parser} with the LL-parsing algorithm
(\cref{algorithm:ll-parser}), we see that they both begin with popping a stack
symbol. More similarities are apparent, after observing that the next
symbol to read or parse, denoted by~$X$ in \cref{algorithm:ll-parser} is obtained
by extracting the symbol~$Y$ that follows the dot in the item~$X$ in
\cref{algorithm:rll-parser}.

In some ways, our \RLLp emulates an \LLp except that it attaches to each symbol
the rule in which it was found and the location within this rule.
(Thus, a push of single item is equivalent to the loop of push operations in
line 22 in \cref{algorithm:ll-parser}).

Function~$Δ(·,·)$, the transition function of an \RLLp is also a bit more
general, and may command the algorithm to push a sequence of stack symbols
(items), or carry out a jump into the stack.

\subsection{The Jump Stack Map Structure}
\label{section:jump}
We still need to explain how the meaning jump operations of \RLLp (lines~5
and~32 in \cref{algorithm:rll-parser}) are implemented.  For this purpose, we
construct here the \emph{\textbf Jump \textbf Stack \textbf Map} (JSM).

Let~$S₀$ be the implicit stack of items used by the \RLLp, and suppose that
this stack is implemented as a singly linked list of nodes of an appropriate
type. Then, the top item of the stack is represented by a pointer, called the
‟\emph{top pointer}”.

The top pointer can be used for pushing or popping from the list. It can
also be used for pushing into the stack a pre-made string of items as done in
line 28 of the algorithm.

Storing pointers into designated items that lie deeper in the stack makes it
possible to make a direct jump into these items. We call these pointers
‟jump pointers” and use~$J$ to denote the type of these.

Let us now build on top of~$S₀$ an abstract data type~$D$, which can thought of
as a stack of dictionaries,
supporting ordinary push and pop operations:
\[
  D=dₙ⋯d₁\$
\]
where~$dᵢ$,~$i=1…n$ is a (partial) map of the type~$Σ↛J$ ($Σ$ being our
alphabet,~$d_n$ being the top of the stack and~$d_1$ the last item in the stack).

Sending query~$\Function get(t)$ to~$D$,~$t∈Σ$ returns the~$J$ value
associated with~$t$ in in the top most (maximal~$i$)~dictionary~$dᵢ$, which
satisfies~$t∈dᵢ$. The query returns~$⊥$ if~$t$ is not found in any of
the~$dᵢ$s.

There is an efficient implementation of~$D$ in which~$\Function get(t)$
is~$O(1)$ time, regardless of the depth at which~$t$ is found in~$D$, while
keeping updates of the form~$\Function push(d)$ or~$d←\Function pop()$
  in~$O(|d|)$ time ($|d|$ being the size of the partial function).

In fact, since~$D$ has the same semantics as that of the stack of symbol tables
of dynamically scoped language (such as \TeX~\cite{TeX:79}), we can
rely on the classical method~\cite{Schoe:95} for implementing these

\begin{enumerate}
  \item Maintain a hash table~$H$ mapping each~$t∈Σ$ to a \emph{stack}~$s(t)$
        of values of type~$J$. A search for key~$t\inΣ$, then returns in~$O(1)$
        time the value at the top of~$s(t)$ or~$⊥$ if stack~$s(t)$ is empty.

  \item The call~$\Function push(d)$,~$|d|=m$ is implemented in~$O(m)$ time. Let
        \[
          d=❴(t₁,j₁),…,(tₘ,jₘ)❵.
        \]
        Then iterate over the pairs~$(tᵢ, pᵢ)$,~$i=1,…,m$,
        pushing~$pᵢ$ to stack~$s(tᵢ)$.

        The call~$\Function push(d)$ terminates by pushing~$d$ itself
        (represented, say, as linked list) as a single item into an auxiliary stack,
        to be denoted~$S₁$.

  \item Thus, abstract data type~$D$ is implemented as the pair~$⟨S₁,H⟩$.

        When~$D$ pops a map~$d$, it uses~$S₁$ to locate~$d$, and just before
        returning it, the implementation of~$D$ uses this~$d$ to pop an element
        from the set~$s(dᵢ)$ of stacks in~$H$,
        \[
            s(dᵢ) = ❴s(t) \;|\; t∈dᵢ❵.
        \]
\end{enumerate}

Let us now generalize~$D$ so that it also supports jumps into it. To do so, let
clients of~$D$ store pointers to designated dictionaries in the stack~$S₁$.

Upon jumping to a deep dictionary~$dᵢ$, our generalized~$D$ must be able to do
a constant time jumps in all stacks in~$s(dᵢ)$.

For this to happen we equip each~$dᵢ$ in the stack~$S₁$ with the correct jump
pointers into the these stacks.
The value of these jump pointers is set as the top pointers of stacks~$s(t)$ at
the time~$dᵢ$ was pushed into~$D$.

A jump into~$D$, yielding a dictionary of size~$m$ can now be implemented
  in~$O(m)$ time:
The jump pointer into stack~$S₁$ yields a dictionary~$d$ stored in it.
In~$d$ we find~$m$ jump pointers into the~$m$ stacks~$s(d)$ in~$H$,
  carrying out the these~$m$ jumps, concludes the jump operation on~$D$.

The final step in constructing the JSM is by coordinating
  stacks~$S₀$ and~$S₁$:
  \begin{itemize}
      \item A push operation on stack $S_0$ is required to push, a potentially
        empty dictionary into the stack $S_1$. 
      \item Augment items in stack~$S_0$  to include also the jump pointer to
        the dictionary it pushed into $S_1$.
      \item Let a jump into stack $S_0$ also 
          force a jump into the stack $S_1$.
          (As expected, a jump into an item $i$ means also a jump
            in stack $S_1$ to dictionary $d_i$.)
  \end{itemize}
Thus, the JSM data structure supports both 
  jumps into the items stack, but also maintaining 
  a current map of the jumps to carry out at each item.
This map is updated with every push, which might
  override (or add) entries to it. 
Most importantly, this map is correctly restored
  in the process of long jumps into the items stack.

How should the JSM be dealt with by the algorithm that generates 
  a specific \RLLp?
Jump operations are all handled at run time,
  using information available on the JSM.
The generator of \RLLp must however tell the \RLLp how to
  update the $S_1$ in the push operations (lines~18 and~28) in 
  \cref{algorithm:rll-parser}.

Thus, our RLL generator must not only supply values for the $Δ$ transition
  function, but also appropriate modification to the dictionary.  

\subsection{Solving the Substitution Factor \texorpdfstring{$k'>0$}{k'>0}
problem}
The section uses the \RLLp described in~\cref{section:realtime} to solve the
problems presented in~\cref{section:intuition} and encode it using \Java
Generics.

In \cref{substitution-factor}~$k'$ was defined and it was shown problematic
when~$k'>0$. The problem relies in the need to perform several substitutions
of the top of the stack with the next rule without consuming the input token.

What we would like to have, is a ‟big” substitution that composes all
consecutive substitutions, i.e., upon seeing the top of the stack and the input
token, the \RLLp in one step will perform all substitutions.

The problem was presented for the \LLp rather then for the \RLLp, but it
exists almost at the same form in the \RLLp. Following is a redefinition
of~$k'$ for the \RLLp.

\begin{Definition}[$k'$ - \RLLp's subtitution factor]
  \label{sll-substitution-factor} Let~$\<A>::=Y₀…Y_{i-1}·Yᵢ…Yₖ$ be the item at
  the top of the stack and~$t$ be the next input symbol. If~$t∈\Function
  First(Yᵢ…Yₖ)$ then~$k'$ is the number of consecutive substitutions the parser
  will perform (replacing the item at the top of the stack with one
  of~$\<Y\ensuremath{ᵢ}>$'s rules) until~$t$ will be consumed from the input.
\end{Definition}

An important observation is that when computing~$k'$, the computation does not
use the information \emph{inside} the stack, but only the very top of the
stack. This observation can be made solely because~$t$ is in~$\Function
First(Yᵢ…Yₖ)$ which ensures that~$t$ will be consumed while parsing~$Yᵢ…Yₖ$.
The result of this observation is that for every item, we can compute the
wanted ‟big” substitution statically (without running the \RLLp on any input).

Since we need the \RLLp to emulate the sequence of operations the \LLp would
perform on an equivalent state, and because of the observation we just made
(that the stack can only only grow is such cases), we need an algorithm
that calculates the ‟closure” of the operations that the \LLp would perform,
i.e.,how would the stack grow.

In~\cref{algorithm:rll-closure} the algorithm for computing this ‟closure” of
\LLp operations is shown.

\begin{algorithm}
  \caption{\label{algorithm:rll-closure}
    An algorithm for computing~$\Function Closure(i,t)$ the closure
    of operations that will happen upon seeing item~$i$ at the top
    of the \RLLp's stack and terminal~$t∈Σ∪❴\$❵$ at the input string.
    Output is returned in~$S$.
  }
  \begin{algorithmic}
    \STATE{$[X::=α·Yβ] ← i$} \COMMENT{break~$i$ into its components}
    \LET{$S$}{$∅$} \COMMENT{initialize output stack}
    \WHILE[loop while~$Y$ is a nonterminal]{$Y∉Σ$}
      \STATE{$r←δ(Y,t)$} \COMMENT{next rule to apply}
      \STATE{$\Function print(r)$} \COMMENT{useful for parsing}
      \STATE{$\Function push(S,[X ::=αY·β])$}\COMMENT{advance the item}
      \STATE{$B::=X₀…Xₘ←r$} \COMMENT{break~$r$ into its components}
      \IF[$δ$ returned an~$ε$-rule]{$X₀…Xₘ=ε$}
        \WHILE[pop all parsed rules]{$\Function parsed(\Function peek(S))$}
          \STATE{$\Function pop(S)$}
        \ENDWHILE
      \ELSE[$δ$ returned a non~$ε$-rule]
        \STATE{$\Function push(S,r)$} \COMMENT{we now turn to parse~$r$}
      \FI
      \STATE{$[X::=α·Yβ] ← \Function pop(S)$} \COMMENT{break~$i$ into its components}
    \ENDWHILE
    \STATE{$\Function push(S,[X ::=αY·β])$} \COMMENT{$Y$ must be~$t$}
    \RETURN{$S$} \COMMENT{return the items to push}
  \end{algorithmic}
  \vspace{0.3ex}
  \hrule
  \vspace{0.3ex}
  \scriptsize
  \begin{enumerate}
    \item function~$\Function parsed(i)$ receives an item as input
          and returns whether its ‟$·$” is at the end of rule,
          i.e., the rule is fully parsed.
  \end{enumerate}
\end{algorithm}

The algorithm takes as input an item and an input terminal and computes the
list of items that the \RLLp will push until the input terminal will be
consumed (emulating the \LLp operations). The algorithm also prints a list of
applied reductions ; this list can be used to build a parse tree without
additional computation at runtime.

The computation process is rather simple: given an item~$\<X>::=α·Yβ$ and
input symbol~$t∈Σ$, the algorithm iteratively applies the operations the \RLLp
would, keeping in an auxiliary stack the state of the stack as it would in a
normal run.  Since~$t \in \Function First(Y\beta )$, we know the auxiliary
stack's height will never go below 0.  The stack is returned when we find the
terminal in the list of derivations.


\subsection{Main Algorithm}

\begin{algorithm}
  \begin{algorithmic}
    \caption{\label{algorithm:construction-delta}
      Algorithm for construction of~$Δ$.
      For each item and terminal it computes the required operation.
    }
    \FOR[for each item]{$i∈ \Function Items()$}
    \STATE{$[\<A>::=Y₀…Y_{i-1}…Yᵢ…Yₘ]←i$} \COMMENT{break~$i$}
      \IF[$Δ$ doesn't handle terminals]{$Yᵢ∈Σ$}
        \CONTINUE \COMMENT{handle next item.}
      \FI
      \FOR[calculate entry~$\Function Δ(i,t)$]{$t∈Σ$}
        \IF[$t$ is consumed while parsing~$i$]{$t∈\Function First(Yᵢ…Yₘ)$}
          \LET{$l$}{$\Function Closure(i,t)$} \COMMENT{use closure table}
          \STATE{$\Function Δ(i,t)= \Function Push(l)$} \COMMENT{a push operation}
          \ELSIF[$t$ is consumed after parsing~$i$]{$t∈\Function Follow(\<A>)$}
          \STATE{$\Function Δ(i,t)= \Function Jump(t)$} \COMMENT{a jump operation}
        \FI
      \ENDFOR
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

