\documentclass[nonatbib,preprint,numbers]{sigplanconf}
\authorinfo{Mr.\ U. N. Owen}{}{}
\title{%
\begin{flushright}
  \scriptsize\bfseries
  Software design is language design. \\
    (And vice versa.) \\
  \footnotesize\mdseries\itshape
   a programmers' proverb
\end{flushright}
  \Huge \Fajita \\ 
  \huge \itshape \textbf Fluent \textbf API for \textsc{\textbf Java} \\
  \LARGE (\textbf Inspired by the \textbf Theory of \textbf Automata)
}
\usepackage{\jobname}

\begin{document}
\maketitle

\begin{abstract}
  \input{abstract}
\end{abstract}

Must include in a place that would not be missed.
\begin{itemize}
  \item \Prolog Unification.  We investigated wildcards, intersection types and
        (the rather limited) type inference of Java, but failed to employ these to
        increase the expressive power of the computation model.
        \item~$aⁿbⁿcⁿ$
\end{itemize}

\section{Introduction}
\input{aa}

\paragraph{Outline.} 
\Cref{Section:proposal} 
  explains how \Fajita may serve the designer of a fluent API. 
Then, \Cref{Section:theoretical-background} discusses the 
  the core computational theory problem that \Fajita 
  needs to solve: recognizing and parsing of formal languages
  within the framework of the limited abilities of \Java
  generics.
The language recognition algorithm that \Fajita
  implements is the subject of \cref{Section:recognizer}.
The main ideas behind the bootstrapping definition of \Self 
  are revealed in \Cref{Section:bootstrapping}. 
\Cref{Section:zz} concludes. 




\textbf{Outline.} \small
\Cref{Section:fluent} is a brief reminder of method chaining,
  and fluent APIs, accompanied a discussion of how this work is related to type states.
It is followed by a similar reminder of context-free languages, pushdown automata,
  and such in \cref{Section:pushdown}.
Based on the vocabulary established this far,
  the main result is stated in~\cref{Section:result}.

Towards the proof in \cref{Section:proof}, \cref{Section:toolkit}
  shows idioms and techniques for encoding computation with
  the \Java type-checker.
\Cref{Section:jump} makes use of these for encoding
  ‟jump-stack”, a non-trivial data-structure,
  which is used, with suitable modifications, in the proof.

In \cref{Section:applicability}, we discuss the challenges in
  translating the proof into a compiler-compiler for fluent APIs.
In particular, this section demonstrates our claim (that may be
  surprising to some) that the standard \Java compiler may spend
  an exponential time on compiling rather simple programs.
\cref{Section:zz} concludes with directions for further research.
\normalsize

\section{Method Chaining, Fluent APIs, and, Type States}
\label{Section:fluent}
\input{fluent}

\section{The \Fajita Language Recognizer}
\label{Section:recognizer}
\input recognizer

\section{Context-Free Languages and Pushdown Automata: Reminder and Terminology}
\label{Section:pushdown}
\input{pushdown}

\section{Statement of the Main Result}
\label{Section:result}
\input{result}

\section{Techniques of Type Encoding}
\label{Section:toolkit}
\input{toolkit}

\section{The Jump-Stack Data-Structure}
\label{Section:jump}
\input{jump}

\section{Proof of \Cref{Theorem:Gil-Levy}}
\label{Section:proof}
\input{proof}

\section{The Prefix Theorem}
\label{Section:prefix}
\input{prefix}

\section{Notes on Practical Applicability}
\label{Section:applicability}
\input{applicability}

\section{Conclusion and Future Work}
\label{Section:zz}
\input{zz}

% \textbf{Acknowledgment.}
% Inspiring correspondence with Gilad Bracha is gratefully acknowledged.

\bibliographystyle{abbrv}\small
\bibliography{author-names,other-shorthands-abbreviated,%
 publishers-abbreviated,%
 conferences-abbreviated,%
 journals-abbreviated,journals-full,%
 yogi-book,yogi-practice,yogi-journal,yogi-tr,%
 GPCE,OOPSLA,PLDI,USENIX,ECOOP,%
 00,yogi-confs}

\clearpage
\appendix
\section{The JLR Recognizer}
\input algorithm

\end{document}

Processing programming languages
\begin{description}
 \item[Lexical analysis] - the first step of the process in which the character strings generated by the
 programmer are aggregated to the abstract tokens defined by the language designer.
 \item[Syntactical analysis (parsing) ] - the second step, in which the processed strings of tokens
 conform to the rules of a formal grammar defined by the language's BNF (or EBNF).
 \item[Semantical analysis] - the next step, usually performed in unison with the previous step,
 in which the legal token sequences are given their semantic meaning.
\end{description}
Specifically, the proposal is that API design of follows the footsteps of
Accordingly, the designer of a fluent API has to follow these three conceptual
steps.
First is the identification of the \emph{vocabulary}, i.e.,
the set of method calls including type arguments that may take part in the
fluent API\@.
In this fluent API example
\begin{JAVA}
allowing (any(Object.class))
 ¢¢.method("get.*")
 ¢¢.withNoArguments();
\end{JAVA}
then, there are three method calls, and the vocabulary has three items in it.
\begin{itemize}
 \item~$ℓ₁ = \cc{any(Class<?>)}$
 \item~$ℓ₂ = \cc{allowing($ℓ₁$)}$
 \item~$ℓ₃ = \cc{method(String)}$
 \item~$ℓ₄ = \cc{withNoArguments()}$
\end{itemize}
