%! TEX root = 00.tex
Formal presentation of the algorithm that compiles an LL(1) grammar into an implementation of a
  language recognizer with \Java generics
  is delayed to the next section.
This section gives an intuitive perspective on this algorithm:

We will first recall the essentials of the classical LL(1) parsing algorithm (\cref{section:essentials}).
Then, we will explain the limitations of the computational model
offered by \Java generics (\cref{section:limitations}).

The discussion proceeds to the observation
  that underlies our emulation of the parsing algorithm
  within these limitations.

Building on all these, \Cref{section:generation} can
  make the intuitive introduction to the main algorithm.
To this end, we revise the classical algorithm for converting
  an LL(1) grammar into an LL(1) parser, and explain
  how it is modified to generate a recognizer executable
  on the computational model of \Java generics.

\subsection{LL(1) Parsing}
\label{section:essentials}
An LL(1) parser is a DPDA allowed to peek at the next input symbol.
Thus,~$δ$, its transition function, takes two parameters: the current state of
the automaton, and a peek into the terminal next to be read.
The actual operation of the automaton
  is by executing in loop the step
  depicted in \cref{algorithm:ll-parser}.

\renewcommand\algorithmicdo{\textbf{\emph{}}}
\renewcommand\algorithmicthen{\textbf{\emph{}}}
\begin{algorithm}[p]
  \caption{\label{algorithm:ll-parser}
  DPDA algorithm for an LL(1) parsing step}
  \begin{algorithmic}
      \LET{$X$}{\Function pop()}\COMMENT{what's anticipated on input?}
      \IF[ancipated~$X$ is a terminal]{$X∈Σ$}
      \IF[read terminal is not anticipated~$X$]{$X≠\Function next()$}
      \STATE{\textsc{Reject}}\COMMENT{automaton halts in error}
      \ELSE[terminal just read was the anticipated~$X$]
      \STATE{\textsc{Continue}}\COMMENT{restart, popping a new~$X$, etc.}
        \FI
      \ELSIF[anticipating end-of-input]{$X=\$$}
        \IF[not the anticipated end-of-input]{$\$≠\Function next()$}
          \STATE{\textsc{Reject}}\COMMENT{automaton halts in error}
          \ELSE[terminal just read was the anticipated~$X$]
          \STATE{\textsc{Accept}}\COMMENT{all input successfully consumed}
        \FI
      \ELSE[anticipated terminal~$X$ must be a nonterminal]
      \LET{$R$}{$\Function δ(X, \Function peek())$}\COMMENT{which rule to reduce?}
      \IF[no rule found]{$R=⊥$}
          \STATE{\textsc{Reject}}\COMMENT{automaton halts in error}
        \ELSE[A rule was found]
        \LET{$(Z ::= Y₁,…,Yₖ)$}{R}\COMMENT{break~$R$ into left/right}
      \STATE{\textbf{assert}~$Z=X$}\COMMENT{$δ$ constructed to return valid~$R$ only}
          \STATE{$\Function print(R)$}\COMMENT{rule~$R$ has just been applied}
          \STATE{\textbf{For}~$i=k,…,1$,~$\Function push(Yᵢ)$}\COMMENT{push in reverse order}
      \STATE{\textsc{Continue}}\COMMENT{restart, popping a new~$X$, etc.}
        \FI % No rule found
      \FI % Main
\end{algorithmic}
  \vspace{0.3ex}
  \hrule
  \vspace{0.3ex}
  \scriptsize
  \begin{enumerate}
      \item
  Input is a string of terminals drawn from alphabet~$Σ$, ending
  with a special symbol~$\$\ni Σ$.
      \item
  Stack symbols are drawn from~$Σ∪❴\$❵∪Ξ$, where~$Ξ$ is
the set of nonterminals of the grammar from which the automaton was generated.
\item
  Functions~$\Function pop()$ and~$\Function push(·)$
  operate on the push-down stack; function~$\Function next()$ returns
  and consumes the next terminal from the input string;
  function~$\Function peek()$ returns this terminal without consuming it.
\item
The automaton starts with the stack with the start symbol~$S∈Ξ$ pushed
  into its stack.
  \end{enumerate}
\end{algorithm}

The DPDA maintains a stack of ‟anticipated” symbols, which may
  be of three kinds: a terminal drawn from the input alphabet~$Σ$,
  an end-of-input symbol~$\$$, or one of~$Ξ$, the set of
  nonterminals of the underlying grammar.

If the top of the stack is an input symbol or the special,
 end-of-input symbol~$\$$, then it must match the next terminal
 in the input string, the matched terminal is then consumed from
 the input string.
If there is no match, the parser rejects.
The parser accepts if the input is exhausted with
  no rejections (i.e.,~$\$$ was matched).

The more interesting case is that~$X$, the popped symbol
  is a nonterminal: the DPDA peeks into the next terminal in the input
  string (without consuming it).
Based on this terminal, and~$X$ the transition function~$δ$
  determines~$R$ the derivation rule to use in order to derive~$X$.
The algorithm rejects if~$δ$ can offer no such rule.
Otherwise, it pushes into the stack, in reverse order, the symbols
  found in the right hand side of~$R$.

\subsection{LL(1) Parsing with \Java Generics?}
\label{section:limitations}
Can \cref{algorithm:ll-parser} be executed on the machinery
  available with \Java generics?
As it turns out, most operations conducted by the algorithm
  are easy.
The implementation of function~$δ$ can
  be found in the toolbox\cref{what-toolbox}.
Similarly, any fixed sequence of push and pop
  operations on the stack can be conducted within a \Java
  transition function:
  the ‟\textbf{For}" at the algorithm can be unrolled.

Superficially, the algorithm appears to be doing a constant amount
  of work for each input symbol.
A little scrutiny falsifies such a conclusion.

In the case~$R=X→Y$,~$Y$
  being a nonterminal, the algorithm will conduct
  a~$\Function pop(·)$ to remove~$X$ and a~$\Function push(·)$
  operation for~$Y$ before consuming a terminal from the input.
Further,~$δ$ may return next the rule~$Y→Z$,
  and then the rule~$Z→Z'$, etc.
Let~$k'$ be the number of such substitutions
  occurring while reading a single input token.

Also, in the case~$R=X→ε$ the DPDA does not push
  anything into the stack.
Further, in its next iteration, the DPDA conducts another
pop,
\[
  X'←\Function pop(),
\]
instruction and proceeds to consider this new~$X'$.
If it so happens, it could also be the case
  that the right hand side of rule~$R'$
  \[
    R' = δ(X', \Function peek())
  \]
  is once again empty,
  and then another~$\Function pop()$
    instruction occurs
\[
  X”←\Function pop(),
\]
  etc.
Let~$k^*$ be the number
  of such instructions in a certain such mishap.

  The cases~$k' > 0$ and~$k^*$ are not rarities.
For example, let us concentrate on the grammar
  depicted in \cref{figure:running}.
This grammar, inspired by the prototypical
  specification of \Pascal \urlref{http://www.fit.vutbr.cz/study/courses/APR/public/ebnf.html},
  shall serve as our running example.

\newsavebox{\Alphabet}
\begin{lrbox}{\Alphabet}
  \begin{tabularx}{0.40\linewidth}{l}
    \cc{program}, \cc{begin}, \cc{end},⏎
    \cc{label}, \cc{const}, \cc{id},⏎
    \cc{procedure},~\cc{;}, \cc{()}
  \end{tabularx}
\end{lrbox}

\begin{figure}[H]
  \caption{\label{figure:running}
    An LL(1) grammar over the alphabet
    \[
      Σ = \left❴\usebox\Alphabet\right❵.
    \]
    (inspired by the original \Pascal grammar; to serve as
    our running example)
  }
  \begin{Grammar}
    \begin{aligned}
      \<Program> & ::= \cc{program} \cc{id} \<Parameters>~\cc{;} \<Definitions>\~\<Body>\hfill⏎
      \<Body> & ::= \cc{begin} \cc{end}\hfill⏎
      \<Definitions> & ::= \<Labels>\~\<Constants>\~\<Nested>\hfill⏎
      \<Labels> & ::= ε \| \cc{label} \<Label>\~\<MoreLabels> \hfill⏎
      \<Constants> & ::= ε \| \cc{const} \<Constant>\~\<MoreConstants> \hfill⏎
      \<Label> & ::=\cc{;} \hfill⏎
      \<Constant> & ::=\cc{;} \hfill⏎
      \<MoreLabels> & ::= ε \| \<Label>\~\<MoreLabels>\hfill⏎
      \<MoreConstants> & ::= ε \| \<Constant>\~\<MoreConstants>\hfill⏎
      \<Nested> & ::= ε \| \<Procedure>\~\<Nested> \hfill⏎
      \<Procedure> & ::= \cc{procedure} \cc{id} \<Parameters>~\cc{;} \<Definitions> \<Body> \hfill⏎
      \<Parameters> & ::= ε \| \cc{()} \hfill⏎
    \end{aligned}
  \end{Grammar}
\end{figure}

The grammar preserves the ‟theme”
  of nested definitions of \Pascal,
  while trimming these down as much as possible.

In order to demonstrate the problems with~$k'$ and~$k^*$ we first
  supply the~$\Function First(·)$, and~$\Function Follow(·)$
  sets of our example grammar.
The~$\Function First(·)$ set of nonterminal~$A$ is the set of all
  terminals that might appear at the beginning of a string derived by~$A$.
The~$\Function Follow(·)$ set of nonterminal~$A$ is the set of all
  terminals that might appear immediately after a string that was
  derived from~$A$.

For example, the nonterminal \nonterminal{Definitions} can be derived to a string
  beginning with \cc{label} (if there are defined labels), or \cc{const}
  (if there are no labels defined), or \cc{procedure} (if there are no
  labels or constants defined).
$\Function Follow(\nonterminal{Definitions})$ on the other hand, contains only
\cc{begin} since~\nonterminal{Definitions} is always followed by~\nonterminal{Body},
  and~$\Function First(\nonterminal{Body})$ contains only \cc{begin}.

The~$\Function First(·)$ and~$\Function Follow(·)$ sets for
  our running example (\cref{figure:running}) are listed in~\cref{table:running-first-follow}.

\begin{table}[H]
  \def\<#1>{\textcolor{black}{\text{$\langle\nonterminal{#1}\rangle$}}}
  \caption{\label{table:running-first-follow}
    Sets~$\Function First(·)$ and~$\Function Follow(·)$ for nonterminals of 
    the grammar in~\cref{figure:running}}
    \begin{tabular}{@{}@{}*3l@{}@{}}
      \toprule
    Nonterminal & $\Function First(·)$ & $\Function Follow(·)$⏎
      \midrule
    \<Program> & \cc{program} & $∅$⏎
    \<Labels> & \cc{label} & \cc{const}, \cc{procedure}, \cc{begin}⏎
    \<Constants> & \cc{constant} & \cc{procedure}, \cc{begin}⏎
    \<Label> & \cc{;} & \cc{;}, \cc{const}, \cc{procedure}, \cc{begin}⏎
    \<MoreLabels> & \cc{;} & \cc{const}, \cc{procedure}, \cc{begin}⏎
    \<Constant> & \cc{;} & \cc{;}, \cc{procedure}, \cc{begin}⏎
    \<MoreConstants> & \cc{;} & \cc{procedure}, \cc{begin}⏎
    \<Nested> & \cc{procedure} & \cc{begin}⏎
    \<Procedure> & \cc{procedure} & \cc{procedure}, \cc{begin}⏎
    \<Definitions> & \cc{label}, \cc{const} & \cc{begin}⏎
      &\cc{procedure} &⏎
    \<Body> & \cc{begin} & \cc{procedure}, \cc{begin}⏎
    \<Parameters> & \cc{()} & \cc{;}⏎
      \bottomrule
  \end{tabular}
\end{table}

\subsubsection{Examples for~$k'$ for the grammar in~\cref{figure:running}}
Consider a state of the parser, in which~$\nonterminal{Definitions}$ is on 
  the top of the top of the stack, and the next token on the input string 
  is \cc{label}.
Until that token is consumed, the parser will:
  \begin{enumerate}
    \item pop~$\nonterminal{Definitions}$ from the stack, and push the
      nonterminals $\nonterminal{Labels}$,~$\nonterminal{Constants}$, and~$\nonterminal{Nested}$
      in reversed order.
    \item pop~$\nonterminal{Labels}$ and push the
      symbols~$\cc{label}$,~$\nonterminal{Label}$, and
      $\nonterminal{MoreLabels}$ in reversed order.
    \item match the top of the stack~\cc{label} with the input symbol~\cc{label}
      and consume it.
  \end{enumerate}
Since we first substituted~$\nonterminal{Definitions}$, then~$\nonterminal{Labels}$
  and only then consumed the input symbol,~$k'=2$.

The problem is that every such operation is 
  an~$ε$-move of the parser's DPDA, and as was shown in~\cref{ECOOP-PAPER}
  it causes problems when we want to employ \Java's compiler to ``run'' our
  automaton.

Another case is when encountering~$\nonterminal{Nested}$ on the top of the stack
  and \cc{procedure} in the input string.
  $k'=2$ again, where at first the non-$ε$ rule of~$\nonterminal{Nested}$ will
  be pushed, then the non-$ε$ rule of~$\nonterminal{Procedure}$ will be
  pushed, and only then will the terminal~\cc{procedure} will match,
  and be consumed from the input string.

\subsubsection{Examples for~$\k^*$ for the grammar in~\cref{figure:running}}
Consider a state in which the parser is in, where the
  only rule of~$\nonterminal{Program}$ is being processed,~$\nonterminal{Definitions}$
  was just replaced on the stack by it's only rule, and~$\nonterminal{Body}$ is below.
Assume also, that the first terminal in the input string is \cc{begin}.

Until the next input token will be consumed, the following will happen:
  \begin{enumerate}
    \item consulting with~$δ$,~$\nonterminal{Labels}$'s~$ε$-rule will
      be chosen, thus,~$\nonterminal{Labels}$ will be popped from the stack.
    \item then the same will happen with~$\nonterminal{Constants}$ and~$\nonterminal{Nested}$.
    \item only after seeing nonterminal~$\nonterminal{Body}$ shall the right rule will be
      pushed, and the token matched.
  \end{enumerate}
In this case,~$k^*=3$ because we had to pop three nonterminals and ‟replace” them with
  their matching rules, that are all~$ε$-rules before we got to a nonterminal
  that will derive to something other then~$ε$.

In the last example~$k^*$ was determined by the size of~$\nonterminal{Definitions}$, but that
  doesn't have to be the case all the time.
For example, if in our grammar, in~$\nonterminal{Program}$'s rule,
  nonterminal~$\nonterminal{Parameters}$ would follow~$\nonterminal{Definitions}$,
  then in the last example, after popping~$\nonterminal{Labels}$,~$\nonterminal{Constants}$
  and~$\nonterminal{Nested}$, nonterminal~$\nonterminal{Parameters}$ would also be popped
  for similar reasons, and~$k^*$ would have been~$4$ in this case.

Again, the problem relies with the multiple pops that occur without reading the input.

  

\endinput
% OLD

\subsection{Generation of LL(1) DPDA Parsers}
\label{section:generation}
% How can we encode it?
The corresponding \Java fluent API ought to have equivalent features.
The input string - since we transform each
  terminal to a method invocation, it is clear that the rest of the input is
  simply the rest of the method chain.
The current state of the parsing is transformed into a \Java type
  (\kk{class} or \kk{interface}) ; this way we can control for each state
  which operation can be made by determining the method of that type.
The environment is realized by type arguments of the states' \Java types.

Using these transformers, we can describe a state of the parser,
  with different stacks using a single type.
This is of course necessary in order to describe all posible configurations
  in a finite number of \Java types.

%
\subsection{LL states}
A state during the parser's computation is a grammar rule~$r = A→αβ$, and an
index in it, i.e.,~$A→α·β$.
It means that the parser is currently processing rule~$r$, it already realized parsed string~$alpha$
  from the input, and it expect to parse the string~$β$ next.
The number of states then, produced by \Fajita for a grammar is linear in the grammar size.

\subsection{Environment}

\begin{algorithm}[p]
  \caption{\label{algorithm:llclosure}
  function~$\Function closure(a,b)$: generates a closure of action from the original ll algorithm}
  \begin{algorithmic}
    \INPUT{a nonterminal~$a$}
    \INPUT{a terminal~$b$}
    \OUTPUT{the closure of consecutive actions}
    \LET{$L$}{$[]$}
    \LET{$x$}{$a$}
    \IF{$∀x→α {}.{} b ∉ \Function first(α)$}
      \RETURN{\textrm{reject}}
    \FI
    \WHILE{$\textrm{true}$}
      \IF{$x∈ξ$}
        \STATE{let~$y₁ y₂… yₖ$ be~$α$ s.t.~$∃x→α∈g∧b∈\Function first(α)$}
        \STATE{$\Function append(l,yₖ,y_{k-1},…,y₂)$}
        \STATE{$x=y₁$}
      \ELSE[$x$ must be~$b$]
        \BREAK
      \FI
    \DONE
    \RETURN{$L$}
  \end{algorithmic}
\end{algorithm}
