%! TEX root = 00.tex
Formal presentation of the algorithm that compiles an LL(1) grammar into an implementation of a
  language recognizer with \Java generics
  is delayed to the next section.
This section gives an intuitive perspective on this algorithm:

We will first recall the essentials of the classical LL(1) parsing algorithm (\cref{section:essentials}).
Then, we will explain the limitations of the computational model
offered by \Java generics (\cref{section:limitations}).

The discussion proceeds to the observation
  that underlies our emulation of the parsing algorithm
  within these limitations.

Building on all these, \Cref{section:generation} can
  make the intuitive introduction to the main algorithm.
To this end, we revise the classical algorithm for converting
  an LL(1) grammar into an LL(1) parser, and explain
  how it is modified to generate a recognizer executable
  on the computational model of \Java generics.

\subsection{LL(1) Parsing}
\label{section:essentials}
An LL(1) parser is a DPDA allowed to peek at the next input terminal.
Thus,~$δ$, its transition function, takes two parameters: the current state of
the automaton, and a peek into the terminal next to be read.
The actual operation of the automaton
  is by executing in loop the step
  depicted in \cref{algorithm:ll-parser}.

\renewcommand\algorithmicdo{\textbf{\emph{}}}
\renewcommand\algorithmicthen{\textbf{\emph{}}}
\begin{algorithm}[p]
  \caption{\label{algorithm:ll-parser}
  DPDA algorithm for LL(1) parsing}
  \begin{algorithmic}
      \LET{$X$}{\Function pop()}\COMMENT{what's anticipated on input?}
      \IF[ancipated~$X$ is a terminal]{$X∈Σ$}
      \IF[read terminal is not anticipated~$X$]{$X≠\Function next()$}
      \STATE{\textsc{Reject}}\COMMENT{automaton halts in error}
      \ELSE[terminal just read was the anticipated~$X$]
      \STATE{\textsc{Continue}}\COMMENT{restart, popping a new~$X$, etc.}
        \FI
      \ELSIF[anticipating end-of-file]{$X=\$$}
        \IF[not the anticipated end-of-file]{$\$≠\Function next()$}
          \STATE{\textsc{Reject}}\COMMENT{automaton halts in error}
          \ELSE[terminal just read was the anticipated~$X$]
          \STATE{\textsc{Accept}}\COMMENT{all input successfully consumed}
        \FI
      \ELSE[anticipated terminal~$X$ must be a nonterminal]
      \LET{$R$}{$\Function δ(X, \Function peek())$}\COMMENT{which rule to reduce?}
      \IF[no rule found]{$R=⊥$}
          \STATE{\textsc{Reject}}\COMMENT{automaton halts in error}
        \ELSE[A rule was found]
        \LET{$(Z ::= Y₁,…,Yₖ)$}{R}\COMMENT{break~$R$ into left/right}
      \STATE{\textbf{assert}~$Z=X$}\COMMENT{$δ$ constructed to return valid~$R$ only}
          \STATE{$\Function print(R)$}\COMMENT{rule~$R$ has just been applied}
          \STATE{\textbf{For}~$i=k,…,1$,~$\Function push(Yᵢ)$}\COMMENT{push in reverse order}
      \STATE{\textsc{Continue}}\COMMENT{restart, popping a new~$X$, etc.}
        \FI % No rule found
      \FI % Main
\end{algorithmic}
  \vspace{0.3ex}
  \hrule
  \vspace{0.3ex}
  \scriptsize
  \begin{enumerate}
      \item
  Input is a stream of terminals drawn from alphabet~$Σ$, ending
  with a special symbol~$\$\ni Σ$.
      \item
  Stack symbols are drawn from~$Σ∪❴\$❵∪Ξ$, where~$Ξ$ is
the set of nonterminals of the grammar from which the automaton was generated.
\item
  Functions~$\Function pop()$ and~$\Function push(·)$
  operate on the push-down stack; function~$\Function next()$ returns
  and consumes the next terminal from the input stream;
  function~$\Function peek()$ returns this terminal without consuming it.
\item
The automaton starts with the stack with the start symbol~$S∈Ξ$ pushed
  into its stack.
  \end{enumerate}
\end{algorithm}

The DPDA maintains a stack of ‟anticipated” symbol, which may
  be of three kinds: a terminal drawn from the input alphabet~$Σ$,
  an -end-of=file symbol~$\$$, or,
  or one of~$Ξ$, the set of nonterminals of the underlying
  grammar.

If the state is an input terminal or the special, end-of-file,
  symbol~$\$$, then it must match
  the next terminal found in the input stream.
If no match is found, then the parser rejects.
The parser accepts if the input is exhausted with
  no rejections.

The more interesting case is that~$X$, the popped symbol
  is a nonterminal: the DPDA peeks into the next terminal in the input
  stream (without consuming it).
Based on this terminal, and~$X$ the transition function~$δ$
  determines~$R$ the derivation rule to use in order to derive~$X$.
The algorithm rejects if~$δ$ can offer no such rule.
Otherwise, it pushes into the stack, in reverse order, the symbols
  found in the right hand side of~$R$.

\subsection{LL(1) Parsing with \Java Generics?}
\label{section:limitations}
Can \cref{algorithm:ll-parser} be executed on the machinery
  available with \Java generics?
As it turns out, most operations conducted by the algorithm
  are easy.
The implementation of function~$δ$ can
  be found in the toolbox.
Similarly, any fixed sequence of push and pop
  operations on the stack can be conducted within a \Java
  transition function:
  the ‟\textbf{For}" at the algorithm can be unrolled.

Superficially, the algorithm appears to be doing a constant amount
  of work for each input symbol.
A little scrutiny falsifies such a conclusion.

In the case~$R=X→Y$,~$Y$
  being a nonterminal, the algorithm will conduct
  two~$\Function push(·)$ operations,
  one for~$X$ and one for~$Y$ before consuming a terminal from the input.
Further,~$δ$ may return next the rule~$Y→Z$,
  and then the rule~$Z→Z'$, etc.
Let~$k'$ be the number of such~$\Function push(·)$
  operations in a certain such incident.

Also, in the case~$k=0$ the DPDA does not push
  anything into the stack.
Further, in its next iteration, the DPDA conducts another
pop,
\[
  X'←\Function pop(),
\]
instruction and proceeds to consider this new~$X'$.
If it so happens, it could also be the case
  that the right hand side of rule~$R'$
  \[
    R' = δ(R', \Function peek())
  \]
  is once again empty,
  and then another~$\Function pop()$
    instruction occurs
\[
  X'←\Function pop(),
\]
  etc.
Let~$k^*$ be the number 
  of such instructions in a certain such mishap. 

  The cases $k' > 0$ and $k^*$ are not rarities.
For example, let us concentrate on the grammar 
  depicted in \cref{figure:issue-1}.
This grammar, inspired by the prototypical
  specification of \Pascal \urlref{http://www.fit.vutbr.cz/study/courses/APR/public/ebnf.html},
  shall serve as our running example.

The grammar preserves the ‟theme”
  of nested definitions of \Pascal,
  while trimming these down as much as possible.
The other major difference is that body of
routines must begin with~\cc{(} followed by \cc{begin}
    rather than a single ‟\cc{begin}”.

Some of the~$δ$ function values for this grammar are
\begin{equation}
  δ(n,t) = 3 
\end{equation}

\newsavebox{\Alphabet}
\begin{lrbox}{\Alphabet}
  \begin{tabularx}{0.40\linewidth}{l}
    \cc{program}, \cc{begin}, \cc{end},⏎
    \cc{label}, \cc{const}, \cc{id},⏎
    \cc{procedure},~\cc{;},~\cc{(}, \cc{()}
  \end{tabularx}
\end{lrbox}

\begin{figure}
  \caption{\label{figure:running}
    An LL(1) grammar over the alphabet
    \[
      Σ = \left❴\usebox\Alphabet\right❵.
    \]
    (inspired by the original \Pascal grammar; to serve as
    our running example)
  }
  \begin{Grammar}
    \begin{aligned}
      \<Program> & ::= \cc{program} \cc{id} \<Parameters>~\cc{;} \<Definitions>\~\<Body>\hfill⏎
      \<Body> & ::= \cc{begin} \cc{end}\hfill⏎
      \<Definitions> & ::= \<Labels>\~\<Constants>\~\<Nested>\hfill⏎
      \<Labels> & ::= ε \| \cc{label} \<Label>\~\<MoreLabels> \hfill⏎
      \<Constants> & ::= ε \| \cc{const} \<Constant>\~\<MoreConstants> \hfill⏎
      \<Label> & ::=\cc{;} \hfill⏎
      \<Constant> & ::=\cc{;} \hfill⏎
      \<MoreLabels> & ::= ε \| \<Label>\~\<MoreLabels>\hfill⏎
      \<MoreConstants> & ::= ε \| \<Constant>\~\<MoreConstants>\hfill⏎
      \<Nested> & ::= ε \| \<Procedure>\~\<Nested> \hfill⏎
      \<Procedure> & ::= \cc{procedure} \cc{id} \<Parameters>~\cc{;} \<Definitions>~\cc{(} \<Body> \hfill⏎
      \<Parameters> & ::= ε \| \cc{()} \hfill⏎
    \end{aligned}
  \end{Grammar}
\end{figure}



\subsection{Generation of LL(1) DPDA Parsers}
\label{section:generation}
% How can we encode it?
The corresponding \Java fluent API ought to have equivalent features.
The input string - since we transform each
  terminal to a method invocation, it is clear that the rest of the input is
  simply the rest of the method chain.
The current state of the parsing is transformed into a \Java type
  (\kk{class} or \kk{interface}) ; this way we can control for each state
  which operation can be made by determining the method of that type.
The environment is realized by type arguments of the states' \Java types.

Using these transformers, we can describe a state of the parser,
  with different stacks using a single type.
This is of course necessary in order to describe all posible configurations
  in a finite number of \Java types.

%
\subsection{LL states}
A state during the parser's computation is a grammar rule~$r = A→αβ$, and an
index in it, i.e.,~$A→α·β$.
It means that the parser is currently processing rule~$r$, it already realized parsed string~$alpha$
  from the input, and it expect to parse the string~$β$ next.
The number of states then, produced by \Fajita for a grammar is linear in the grammar size.

\subsection{Environment}

\begin{algorithm}[p]
  \caption{\label{algorithm:llclosure}
  function~$\Function closure(a,b)$: generates a closure of action from the original ll algorithm}
  \begin{algorithmic}
    \INPUT{a nonterminal~$a$}
    \INPUT{a terminal~$b$}
    \OUTPUT{the closure of consecutive actions}
    \LET{$L$}{$[]$}
    \LET{$x$}{$a$}
    \IF{$∀x→α. b ∉ \Function first(α)$}
      \RETURN{\textrm{reject}}
    \FI
    \WHILE{$\textrm{true}$}
      \IF{$x∈ξ$}
        \STATE{let~$y₁ y₂… yₖ$ be~$α$ s.t.~$∃x→α∈g∧b∈\Function first(α)$}
        \STATE{$\Function append(l,yₖ,y_{k-1},…,y₂)$}
        \STATE{$x=y₁$}
      \ELSE[$x$ must be~$b$]
        \BREAK
      \FI
    \DONE
    \RETURN{$L$}
  \end{algorithmic}
\end{algorithm}
